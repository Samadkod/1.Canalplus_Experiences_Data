# Segmentation des Audiences Sportives ( 1 & 2)

## Introduction

Ce projet présente deux analyses de segmentation d'audience pour des compétitions emblématiques : la **Ligue 1** et la **Ligue des Champions**. Ces analyses offrent des perspectives uniques sur les habitudes de visionnage, permettant de mieux adapter les stratégies de contenu et de fidélisation.

- **Ligue 1** : Segmentation structurée selon des critères définis par les experts métiers, donnant un aperçu précis des préférences régionales.

- **Ligue des Champions** : Une approche plus approfondie, intégrant des calculs d'agrégation, comme l’écart-type des consommations, pour une segmentation fine des comportements de visionnage.

---
### 1. [Segmentation de l'audience des abonnés suivant la Ligue 1](#)

<p align="center">
  <img src="https://www.press-agrum.com/wp-content/uploads/2024/04/pressagrum-logo-liguefeat.jpg" width="1000" height="300" />
</p>

#### Objectif de l'analyse :
- Cette analyse vise à segmenter les abonnés suivant les matchs de la Ligue 1 par zone géographique. Le but est de comprendre les comportements de visionnage, et d'ajuster les stratégies de contenu et marketing pour maximiser l'engagement et réduire le churn (désabonnement).

#### Compétences acquises :
  - [x] Analyse des comportements de visionnage par région.
  - [x] Utilisation de **SQL** pour segmenter les abonnés et les classer en fonction de leur consommation.
  - [x] Synthèse des résultats pour les équipes marketing et métiers.
  - [x] Création de graphiques et visualisations pour représenter l'engagement selon les territoires.

#### Outils utilisés :
- SQL, Excel, Power BI, PowerPoint

---

### 2. [Segmentation des abonnés visionnant la Ligue des Champions via Dataiku](#)

<p align="center">
  <img src="https://www.lyoncapitale.fr/wp-content/uploads/2014/12/523400-ez-Logo-Ligue-des-Champions.jpg" width="1000" height="300" />
</p>

#### Objectif de l'analyse :
- L'objectif de cette analyse est de segmenter les abonnés en fonction de leur **consommation des matchs de la Ligue des Champions (CL)**. En fonction du comportement de visionnage, nous avons créé des groupes d'abonnés (de "rare" à "ultra+") pour mieux comprendre leur engagement et adapter les actions marketing.

#### Compétences acquises :
  - [x] Maîtrise des opérations d'agrégation pour calculer la moyenne et l'écart-type des consommations par saison.
  - [x] Création d'un modèle de **segmentation des abonnés** basé sur la durée de consommation.
  - [x] Synthèse des résultats pour les équipes marketing afin de **cibler les actions** en fonction du segment.
  - [x] Automatisation des processus d'analyse via **Dataiku**.

#### Outils utilisés :
- Python, SQL, Power BI, Dataiku, Excel

---
### 3. [Prédiction de churn des abonnés selon leur consommation TV](#)

<p align="center">
  <img src="https://dezyre.gumlet.io/images/blog/churn-models/Customer_Churn_Prediction_Models_in_Machine_Learning.png?w=800&dpr=1.0" width="1000" height="300" />
</p>

- ***Objectif de l'analyse*** :

Le churn, qui désigne la perte d'abonnés, est un indicateur clé pour les entreprises basées sur un modèle d'abonnement. Son analyse permet d'améliorer les services pour réduire ce phénomène.

L'un de mes projets chez Canal+ portait sur l'analyse prédictive du churn. Après un travail approfondi sur la qualité des données, incluant des études exploratoires et de l’ingénierie de données, nous avons développé des modèles de Machine Learning, tels que la régression logistique, les arbres de décision et les forêts aléatoires. Ces modèles nous ont permis de prédire avec précision les abonnés les plus susceptibles de se désabonner, avec pour objectif de réduire significativement le taux de churn.

- ***Compétences*** :
  - [x] Maîtrise des ETL et des jointures SQL complexes
  - [x] Analyse descriptive : compréhension du comportement des abonnés
    - [x] Analyse bivariée des "abonnés fidèles" et "abonnés churners"
  - [x] Revue de littérature sur la modélisation du churn
  - [x] Mise en place de modèles de prédiction du churn
    - [x] Choix des variables pour les modèles de machine learning
    - [x] Sélection de variables pour la régression logistique
  - [x] Génération de graphiques adaptés aux types de données
  - [x] Synthèse des résultats à destination des métiers

### Outils utilisés :
SQL, Excel, Python, PowerPoint

---

### 4. [Analyse de la Performance de la Nuit Bonus en Afrique](#)
- L'objectif de ce projet était d'évaluer la performance des émissions de la **Nuit Bonus**, diffusées en live et en rediffusion, afin de mieux comprendre l'engagement de l'audience.

<p align="center">
  <img src="https://image.over-blog.com/njENmfOTRObRazbfCP8sfwn6DOA=/filters:no_upscale()/image%2F2132870%2F20230920%2Fob_ba7f44_lb190923-06.JPG" width="1000" height="300" />
</p>

- **Competences** 
  - [x] Manipulation de grandes bases de données(Nettoyage et gestions d'anomalie, gestion des doublons et incoherences, des valeurs aberrantes , ainsi que des données manquantes)
  - [x] Calcul du **taux de reach global** et par KPI (formules d'abonnement, pays et chaînes).
  - [x] Identification des forces et axes d'amélioration pour les futures stratégies de diffusion.
  - [x] Génération de graphiques adaptés aux types de données
  - [x] Synthèse des résultats à destination des métiers
        
  - **Résultat** : Optimisation des stratégies de diffusion en identifiant les sous titres ou les periodes les plus engageantes.
 
### Outils utilisés :
SQL, Excel, Python, Power BI, PowerPoint.

---
### 5. [Analyse d'Audience des Chaînes Islamiques de Canal+ en Afrique](#)
- Dans ce projet, l'objectif était de comprendre l'impact du Ramadan sur l'audience des chaînes islamiques, en comparant les comportements de visionnage pendant et en dehors du mois sacré.

<p align="center">
  <img src="https://www.madeforyou-agency.com/medias/jpg/02.canal__international_map_iphone.jpg" width="1000" height="300" />
</p>

**Competences et résultats clés** :
- [x] Analyse de la **part d'audience** et du **taux de reach** des chaînes islamiques via des requêtes **SQL**.
- [x] Détection des variations d'audience en fonction des périodes (Ramadan et hors-Ramadan).
- [x] Insight sur les habitudes de consommation pendant les saisons religieuses.

---

### 6. [Évaluation de la Performance des Chaînes Partenaires](#)
- Ce projet visait à identifier les contenus les plus performants sur les plateformes partenaires de Canal+ , en se basant sur les données d'audience et établir un classement des cinq meilleurs contenus

<p align="center">
  <img src="https://images.frandroid.com/wp-content/uploads/2022/12/canal-disney-paramount-1.jpg" width="1000" height="300" />
</p>

- **Compétences et resultats** :
  - [x] Identification des meilleurs contenus par plateforme, permettant de mieux comprendre les préférences des utilisateurs.
    - [x] Analyse d’audience par plateforme.
    - [x] optimisation des stratégies de contenu.
          
  - **Résultat** : Amélioration de la stratégie de contenu sur les plateformes partenaires grâce à l’identification des meilleures émissions.

---

## 7. [Analyse de la Performance des Créations Originales de Canal+ dans les DROM](#)
- Ce projet portait sur l'évaluation de l'impact des créations originales de Canal+ sur les abonnés des **DROM** (Départements et Régions d'Outre-Mer).

<p align="center">
  <img src="https://thumb.canalplus.pro/bran/unsafe/460x259/filters:quality(80)/image/65534d24a663c/uploads/media/myCANAL_16x9_Logotype_MEA_1920x1080_label.jpg" width="1000" height="300" />
</p>

- Dans le cadre de mon stage, nous avions pour objectif de mesurer l'impact des créations originales de Canal+ sur les abonnés des DROM. Pour cela, nous avons utilisé des techniques d'extraction et d'analyse de données via SQL, complétées par des visualisations en Python, en nous concentrant particulièrement sur le taux de Reach par contenu.

### Compétences :

  - [x] Analyse de l'impact des contenus originaux sur le comportement des consommateurs.
    - [x] Mesure de l'effet des créations originales sur l'engagement des abonnés dans les DROM.
    - [x] Mise en avant du **taux de reach** par contenu original.
  - [x] Génération de graphiques adaptés aux types de données
  - [x] Synthèse des résultats à destination des métiers

### Outils utilisés :
SQL, Excel, Python, PowerPoint

---

### 8. [Extraction du calendrier des matchs de l'Euro 2024, de la ligue 1, du MMA-FC et NBA via l'API Football Data](#)

<p align="center">
  <img src="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:best/rockcms/2024-05/240509-nba-game-ch-1311-f72588.jpg" width="1000" height="300" />
</p>

## Objectif de l'analyse :
- Cette analyse a pour objectif de récupérer automatiquement les **données des matchs de la NBA ou de l'Euro 2024** via l'API Football Data. Nous avons extrait des informations clés comme les **dates de matchs**, **équipes participantes**, et **scores** pour créer un dataset exploitable à des fins d'analyse et de visualisation.
  
  En exploitant ces données en temps réel, il est possible de créer des tableaux de bord pour suivre les performances des équipes ou détecter des tendances de jeu pendant le tournoi.

- **Compétences acquises** :
  - [x] Récupération des données via une API avec une clé d'authentification.
  - [x] Utilisation de **Pandas** pour transformer et organiser les données de manière efficace.
  - [x] Manipulation des données temporelles (séparation des dates et heures).
  - [x] Intégration et stockage des données dans un dataset Dataiku pour des analyses futures.

### Outils utilisés :
Python, Requests, Dataiku

---

### 9. [Classification des abonnés de la Ligue 1 selon leur consommation](#)

<p align="center">
  <img src="https://www.ariase.com/uploads/media/ac1027b89a8b7c11ea60700da77ae9f30282368f.jpeg" width="1000" height="300" />
</p>

## Objectif de l'analyse :
- L'objectif de ce projet est de **classer les abonnés de la Ligue 1** selon leur niveau de consommation, en tenant compte des saisons 2022/2023 et 2023/2024. Cette segmentation permet de distinguer trois catégories d'abonnés : **faible**, **moyen**, et **haut**, en fonction du temps passé à visionner les matchs.
  
En analysant la consommation totale des abonnés, nous pouvons mieux comprendre leur engagement et **cibler les actions marketing** pour améliorer la rétention, notamment pour ceux ayant un engagement faible.

- **Compétences acquises** :
  - [x] Utilisation de **Pandas** pour appliquer des règles de classification sur les abonnés.
  - [x] Segmentation en fonction de la durée totale de consommation des abonnés.
  - [x] Traitement des données via Dataiku et export des résultats pour des analyses futures.

### Outils utilisés :
SQL, Python, Dataiku

---
### 10. [Rapports de performances consolidées OTT|SAT via la conso sur myCANAL dans Dataiku](#)

<p align="center">
  <img src="https://thumb.canalplus.pro/http/unsafe/1344x756/smart/creativemedia-image.canalplus.pro/content/0001/51/39a60c958216bca5cbbb627771daa47bdf18a8ba.png" width="1000" height="300" />
</p>

## Objectif de l'analyse :
- Ce projet vise à **automatiser la génération de rapports de performances** consolidées pour les abonnés OTT/SAT, en incluant la consommation sur **myCANAL**.
- L’objectif est d'extraire automatiquement les abonnés actifs par région chaque semaine, de **lundi à dimanche**, pour fournir une vue d'ensemble des performances de la semaine précédente.

Chaque lundi, les abonnés actifs sont comptabilisés par zone géographique, et un **tableau de bord dynamique** permet de visualiser ces performances de manière interactive. Les équipes métiers reçoivent automatiquement les rapports consolidés via un envoi programmé.

- **Compétences acquises** :
  - [x] Création de requêtes SQL pour extraire automatiquement les données des abonnés actifs par région.
  - [x] Développement de **dashboards dynamiques** pour suivre les performances par zone géographique.
  - [x] Programmation de l'envoi automatique des rapports hebdomadaires aux équipes métiers via Dataiku.

### Outils utilisés :
SQL, Dataiku, Dashboards interactifs

---
### 11. [Reformatage de Code SAS en SQL et Migration vers Dataiku](#)

<p align="center"> <img src="https://cdn.prod.website-files.com/6603bc85bc604431b3053166/6633ecea792854e4f20d13bf_663160c9bd1f9397bc8fafaf_Image-2-1.png" width="1000" height="300" /> </p>

- **Description** :
- L'un des principaux défis de mon stage chez Canal+ a été de reformater le code SAS existant en SQL pour faciliter une meilleure gestion et intégration des données dans Snowflake. Ce projet visait à améliorer la performance, à simplifier la gestion des données et à préparer l’automatisation des processus via Dataiku, une plateforme avancée d’analyse de données.

- Après la conversion du code en SQL, j'ai pris l'initiative de créer des tables adaptées dans Snowflake, optimisant ainsi la manipulation des données. Ensuite, nous avons utilisé Dataiku pour automatiser l'envoi de courriels concernant les projets d’abonnement gratuit, une tâche qui était initialement réalisée manuellement.

- **Compétences acquises** :
- [x] **Reformatage de code** : Conversion du code SAS en SQL pour une intégration plus fluide dans Snowflake.
- [x] **Création et gestion de tables** : Construction de tables adaptées pour améliorer la gestion des données dans Snowflake.
- [x] **Automatisation des processus** : Utilisation de Dataiku pour automatiser les tâches manuelles, notamment l’envoi de courriels, ce qui a significativement amélioré l'efficacité opérationnelle.
      
- **Outils utilisés** :
- SAS pour la gestion initiale des données.
- SQL pour la réécriture du code et la gestion des données dans Snowflake.
- Dataiku pour l’automatisation des processus.
  
- **Résultat** :
Le projet a permis une réduction des erreurs humaines et une amélioration significative de l'efficacité opérationnelle grâce à l’automatisation des tâches répétitives via Dataiku. Cela a libéré du temps pour se concentrer sur des tâches plus stratégiques au sein de l'équipe.

>[!NOTE]
> Ce projet démontre l'importance de l'automatisation dans les grandes entreprises et comment la transformation des workflows peut générer des gains de productivité considérables.
